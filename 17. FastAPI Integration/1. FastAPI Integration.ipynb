{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature / Layer                | Purpose / Usage                                                                                 | Real-Time Example                                   |\n",
    "| ------------------------------ | ----------------------------------------------------------------------------------------------- | --------------------------------------------------- |\n",
    "| **FastAPI Backend**            | Acts as a **data API**, **LLM executor**, or **LangGraph orchestrator** behind Streamlit UI     | Run LangGraph agents in background, Streamlit as UI |\n",
    "| **Async Streaming APIs**       | Enables **real-time token-level output** from LLMs, streamed to Streamlit via `async` endpoints | Chatbot responses, LangGraph tracing                |\n",
    "| **Shared Memory (Redis/etc)**  | Use Redis, SQLite, or file-backed storage to persist user state between UI/API interactions     | Memory sharing across users/sessions                |\n",
    "| **WebSockets**                 | Use FastAPI‚Äôs `WebSocket` support for **live updates** in Streamlit via polling or JS bridge    | Live model output, status updates                   |\n",
    "| **Authentication Middleware**  | Implement login / API key protection for agents using FastAPI middlewares or dependencies       | Secure access to LangGraph or vector DBs            |\n",
    "| **Deployment Gateway**         | Use FastAPI as a **gateway to external services** (RAG APIs, DBs, workflows)                    | Query Pinecone, HuggingFace, etc.                   |\n",
    "| **LangGraph Hosting**          | LangGraph workflows hosted in FastAPI for **multi-step orchestration**, called via Streamlit    | Streamlit triggers ‚Üí FastAPI runs agent nodes       |\n",
    "| **Multi-user Handling**        | Enable session tokenization, header auth, or per-user memory contexts                           | Multi-tenant AI apps                                |\n",
    "| **Streamlit ‚Üî FastAPI Bridge** | Streamlit `requests` or `httpx` calls FastAPI for dynamic routes, model results, chain triggers | `response = requests.post(...)`                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üß© Typical Integration Architecture\n",
    "  [User]\n",
    "    ‚Üì\n",
    "[Streamlit UI]\n",
    "   ‚Üì  REST / WebSocket\n",
    "[FastAPI Backend]\n",
    "   ‚Üì             ‚Üì\n",
    "[LangGraph Workflow]  -> [Vector DB / RAG / Tools / Logs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üì¶ FastAPI Server (main.py)\n",
    "from fastapi import FastAPI, Request\n",
    "from fastapi.responses import StreamingResponse\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "async def chat(request: Request):\n",
    "    data = await request.json()\n",
    "    prompt = data.get(\"prompt\", \"\")\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    chain = LLMChain(llm=llm, prompt=\"Answer: {input}\")\n",
    "    output = chain.run({\"input\": prompt})\n",
    "    return {\"response\": output}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üåê Streamlit App (app.py)\n",
    "import streamlit as st\n",
    "import requests\n",
    "\n",
    "st.title(\"üí¨ Chat with FastAPI LangChain\")\n",
    "prompt = st.text_input(\"Ask something:\")\n",
    "\n",
    "if st.button(\"Send\") and prompt:\n",
    "    res = requests.post(\"http://localhost:8000/chat\", json={\"prompt\": prompt})\n",
    "    st.write(\"ü§ñ\", res.json()[\"response\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-doc-chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
